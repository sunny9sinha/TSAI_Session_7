{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session7_Assignment_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ADsz2HZjUJlQdXM6zpHHgQgbZJ-uivO9",
      "authorship_tag": "ABX9TyPqanr493CGMXDQjF0dc4jB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunny9sinha/TSAI_Session_7/blob/main/Session7_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfLoK_Dse1w7"
      },
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4ZjO9vPJ49z"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        \n",
        "        super().__init__()          \n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # LSTM layer\n",
        "        self.encoder = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        # try using nn.GRU or nn.RNN here and compare their performances\n",
        "        # try bidirectional and compare their performances\n",
        "        \n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [batch size, sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        # packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.encoder(packed_embedded)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "    \n",
        "        # Hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs = self.fc(hidden)   \n",
        "        \n",
        "        # Final activation function softmax\n",
        "        output = F.softmax(dense_outputs[0], dim=1)\n",
        "            \n",
        "        return output"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "6bi-LPmhfXBi",
        "outputId": "491fd272-7cfe-40af-d324-3eeac050c1d8"
      },
      "source": [
        "sentences = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Session5/stanfordSentimentTreebank/datasetSentences.txt',sep='\\t')\n",
        "sentences.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_index                                           sentence\n",
              "0               1  The Rock is destined to be the 21st Century 's...\n",
              "1               2  The gorgeously elaborate continuation of `` Th...\n",
              "2               3                     Effective but too-tepid biopic\n",
              "3               4  If you sometimes like to go to the movies to h...\n",
              "4               5  Emerges as something rare , an issue movie tha..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1MlztN6b3OL",
        "outputId": "62c520ec-327f-4b84-9a00-1646446d15f6"
      },
      "source": [
        "sentences.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11855, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "PBc9KehEg2bF",
        "outputId": "010b7f30-ef71-4136-a5cb-99286747dfa5"
      },
      "source": [
        "sentiment = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Session5/stanfordSentimentTreebank/sentiment_labels.txt',sep='|')\n",
        "sentiment.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.44444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.42708</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   phrase ids  sentiment values\n",
              "0           0           0.50000\n",
              "1           1           0.50000\n",
              "2           2           0.44444\n",
              "3           3           0.50000\n",
              "4           4           0.42708"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILypkYOuhXzf"
      },
      "source": [
        "sentiment_class = []\n",
        "for i in sentiment['sentiment values'] :\n",
        "  if i >=0 and i<0.2:\n",
        "    sentiment_class.append(1)\n",
        "  elif i>=0.2 and i<0.4:\n",
        "    sentiment_class.append(2)\n",
        "  elif i>=0.4 and i<0.6:\n",
        "    sentiment_class.append(3)\n",
        "  elif i>=0.6 and i<0.8:\n",
        "    sentiment_class.append(4)\n",
        "  else:\n",
        "    sentiment_class.append(5)\n",
        "\n",
        "sentiment['sentiment values'] = sentiment_class\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "zn4_U2oyiM7P",
        "outputId": "b1a5ec72-8315-4311-e4f1-a7559eb617d9"
      },
      "source": [
        "sentiment.describe()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>239232.000000</td>\n",
              "      <td>239232.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>119615.500000</td>\n",
              "      <td>3.062391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>69060.474137</td>\n",
              "      <td>0.911298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>59807.750000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>119615.500000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>179423.250000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>239231.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          phrase ids  sentiment values\n",
              "count  239232.000000     239232.000000\n",
              "mean   119615.500000          3.062391\n",
              "std     69060.474137          0.911298\n",
              "min         0.000000          1.000000\n",
              "25%     59807.750000          3.000000\n",
              "50%    119615.500000          3.000000\n",
              "75%    179423.250000          4.000000\n",
              "max    239231.000000          5.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEQqoUbZdqfs",
        "outputId": "1a3b2e68-1956-4648-8f20-3c5df643a600"
      },
      "source": [
        "dataset = pd.merge(left=sentences, right=sentiment, left_on='sentence_index', right_on='phrase ids')\n",
        "dataset = dataset.drop(columns=['phrase ids','sentence_index'])\n",
        "dataset.rename(columns = {'sentiment values':'sentiments'}, inplace = True)\n",
        "print(dataset.shape)\n",
        "print(dataset.head())\n",
        "print(dataset.columns)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11855, 2)\n",
            "                                            sentence  sentiments\n",
            "0  The Rock is destined to be the 21st Century 's...           3\n",
            "1  The gorgeously elaborate continuation of `` Th...           3\n",
            "2                     Effective but too-tepid biopic           3\n",
            "3  If you sometimes like to go to the movies to h...           3\n",
            "4  Emerges as something rare , an issue movie tha...           2\n",
            "Index(['sentence', 'sentiments'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccuG1cmm442m"
      },
      "source": [
        "def smallCase(data):\n",
        "  for i in data.index:\n",
        "    data['sentence'][i] = data['sentence'][i].lower()\n",
        "  return data"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhoH0Y-CynR-",
        "outputId": "ad482ff6-c018-4e05-a218-cb88aa72ffc0"
      },
      "source": [
        "import re\n",
        "def cleanText(data):\n",
        "  data_small_case = smallCase(data)\n",
        "  for i in data_small_case.index:\n",
        "    data_small_case.sentence[i] = re.sub(\"[^-9A-Za-z ]\", \"\" , data_small_case.sentence[i])\n",
        "\n",
        "  return data_small_case\n",
        "\n",
        "dataset = cleanText(dataset)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "5aTW7lDg87Yw",
        "outputId": "d501d619-e2d1-40b8-fbff-43e507feee0f"
      },
      "source": [
        "dataset.head(10)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the rock is destined to be the st century s ne...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the gorgeously elaborate continuation of  the ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>effective but too-tepid biopic</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>if you sometimes like to go to the movies to h...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>emerges as something rare  an issue movie that...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>the film provides some great insight into the ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>offers that rare combination of entertainment ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>perhaps no picture ever made has more literall...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>steers turns in a snappy screenplay that curls...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>but he somehow pulls it off</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  sentiments\n",
              "0  the rock is destined to be the st century s ne...           3\n",
              "1  the gorgeously elaborate continuation of  the ...           3\n",
              "2                     effective but too-tepid biopic           3\n",
              "3  if you sometimes like to go to the movies to h...           3\n",
              "4  emerges as something rare  an issue movie that...           2\n",
              "5  the film provides some great insight into the ...           3\n",
              "6  offers that rare combination of entertainment ...           3\n",
              "7  perhaps no picture ever made has more literall...           2\n",
              "8  steers turns in a snappy screenplay that curls...           3\n",
              "9                       but he somehow pulls it off            3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ5B3Hzgf8Ub"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(dataset, test_size=0.3)\n",
        "train = train.reset_index().drop(columns=['index'])\n",
        "test = test.reset_index().drop(columns=['index'])"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S-fho7Vgy6R",
        "outputId": "cb84815a-906b-46a4-fa6b-d633f2cfced4"
      },
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8298, 2)\n",
            "(3557, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFDmN6Rc-Nu4",
        "outputId": "93a46e38-6fa1-4816-9eba-dfd5d886c96d"
      },
      "source": [
        "test.sentence[1:10]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1                      one-of-a-kind near-masterpiece \n",
              "2    for movie lovers as well as opera lovers  tosc...\n",
              "3    excellent performances from jacqueline bisset ...\n",
              "4     a story  an old and scary one  about the mons...\n",
              "5    a painfully slow cliche-ridden film filled wit...\n",
              "6        a smart  arch and rather cold-blooded comedy \n",
              "7    it does nt reach them  but the effort is grate...\n",
              "8    cremaster  is at once a tough pill to swallow ...\n",
              "9    shadyac shoots his film like an m night shyama...\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2RqZ-tY7EGQ",
        "outputId": "bf7331aa-a609-4291-f6a3-c6f4b347c86f"
      },
      "source": [
        "# Import Library\n",
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext import data \n",
        "\n",
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f2a1f7142f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQccyyC97mWK"
      },
      "source": [
        "sentence = torchtext.legacy.data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "sentiments = torchtext.legacy.data.Field(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkUjjQXK8RZf"
      },
      "source": [
        "fields = [('sentence', sentence),('sentiments',sentiments)]"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUn_viES9Kc5"
      },
      "source": [
        "example = [torchtext.legacy.data.Example.fromlist([train.sentence[i],train.sentiments[i]], fields) for i in range(train.shape[0])] "
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeOydW1cEQO4"
      },
      "source": [
        "trainDataset = torchtext.legacy.data.Dataset(example, fields)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl32EtxiFXXp"
      },
      "source": [
        "example = [torchtext.legacy.data.Example.fromlist([test.sentence[i],test.sentiments[i]], fields) for i in range(test.shape[0])] "
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY7vJroKFsFB"
      },
      "source": [
        "testDataset = torchtext.legacy.data.Dataset(example, fields)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgK4Qo2-F1yA",
        "outputId": "298dbf20-1fe5-4853-bd66-2ea5677528fa"
      },
      "source": [
        "vars(trainDataset.examples[10])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence': ['the',\n",
              "  'plot',\n",
              "  'is',\n",
              "  'romantic',\n",
              "  'comedy',\n",
              "  'boilerplate',\n",
              "  'from',\n",
              "  'start',\n",
              "  'to',\n",
              "  'finish'],\n",
              " 'sentiments': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A15FtRYpHbGA"
      },
      "source": [
        "sentence.build_vocab(trainDataset)\n",
        "sentiments.build_vocab(trainDataset)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-kW8cFGIVs4",
        "outputId": "16f3252d-a4fb-47c7-f070-5908e9815956"
      },
      "source": [
        "print('Size of input vocab : ', len(sentence.vocab))\n",
        "print('Size of label vocab : ', len(sentiments.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(sentence.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', sentiments.vocab.stoi)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  15090\n",
            "Size of label vocab :  6\n",
            "Top 10 words appreared repeatedly : [(' ', 8846), ('the', 7113), ('a', 5066), ('and', 4441), ('of', 4296), ('to', 2998), ('-', 2641), ('s', 2542), ('is', 2466), ('it', 2374)]\n",
            "Labels :  defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7f299d70b810>>, {'<unk>': 0, 3: 1, 2: 2, 4: 3, 5: 4, 1: 5})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yRABmGUI29v"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk38rlxOJAm7"
      },
      "source": [
        "train_iterator, test_iterator = torchtext.legacy.data.BucketIterator.splits((trainDataset, testDataset), batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.sentence),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJFYU6cAJaN6"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(sentence.vocab.stoi, tokens)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj9q1XWcNwHy"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(sentence.vocab)\n",
        "embedding_dim = 200\n",
        "num_hidden_nodes = 300\n",
        "num_output_nodes = 6\n",
        "num_layers = 4\n",
        "dropout = 0.4\n",
        "\n",
        "# Instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers, dropout = dropout)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9BEJoIgOG4W",
        "outputId": "2dcd088c-5b51-49a0-a465-33febc47e4ba"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(15090, 200)\n",
            "  (encoder): LSTM(200, 300, num_layers=4, batch_first=True, dropout=0.4)\n",
            "  (fc): Linear(in_features=300, out_features=6, bias=True)\n",
            ")\n",
            "The model has 5,789,406 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LUXLZIVOPKG"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtV0AFllOc1S"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        # retrieve text and no. of words\n",
        "        sentence, sentence_lengths = batch.sentence  \n",
        "        # convert to 1D tensor\n",
        "        predictions = model(sentence, sentence_lengths).squeeze()  \n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.sentiments)        \n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.sentiments)   \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuQPSX3LPEBA"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            sentence, sentence_lengths = batch.sentence\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(sentence, sentence_lengths).squeeze()\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.sentiments)\n",
        "            acc = binary_accuracy(predictions, batch.sentiments)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzKZXmUdTDo-",
        "outputId": "ca30b649-3ada-4b00-af80-36f4e5d96706"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "best_test_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if test_loss < best_test_loss:\n",
        "        best_test_loss = test_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Test. Loss: {test_loss:.3f} |  Test. Acc: {test_acc*100:.2f}% \\n')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 1.560 | Train Acc: 52.21%\n",
            "\t Test. Loss: 1.534 |  Test. Acc: 51.27% \n",
            "\n",
            "\tTrain Loss: 1.515 | Train Acc: 53.12%\n",
            "\t Test. Loss: 1.534 |  Test. Acc: 51.29% \n",
            "\n",
            "\tTrain Loss: 1.515 | Train Acc: 53.10%\n",
            "\t Test. Loss: 1.534 |  Test. Acc: 51.27% \n",
            "\n",
            "\tTrain Loss: 1.513 | Train Acc: 53.12%\n",
            "\t Test. Loss: 1.534 |  Test. Acc: 51.24% \n",
            "\n",
            "\tTrain Loss: 1.512 | Train Acc: 53.34%\n",
            "\t Test. Loss: 1.533 |  Test. Acc: 51.24% \n",
            "\n",
            "\tTrain Loss: 1.510 | Train Acc: 53.60%\n",
            "\t Test. Loss: 1.534 |  Test. Acc: 51.16% \n",
            "\n",
            "\tTrain Loss: 1.509 | Train Acc: 53.93%\n",
            "\t Test. Loss: 1.533 |  Test. Acc: 51.27% \n",
            "\n",
            "\tTrain Loss: 1.506 | Train Acc: 54.16%\n",
            "\t Test. Loss: 1.535 |  Test. Acc: 50.93% \n",
            "\n",
            "\tTrain Loss: 1.503 | Train Acc: 54.45%\n",
            "\t Test. Loss: 1.533 |  Test. Acc: 51.02% \n",
            "\n",
            "\tTrain Loss: 1.501 | Train Acc: 54.57%\n",
            "\t Test. Loss: 1.536 |  Test. Acc: 50.82% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_5TRZ9lBFmX"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_sentence(sentence):\n",
        "    \n",
        "    #categories = {0: \"very negative\", 1:\"negative\", 2:\"neutral\", 3:\"positive\", 4:\"very positive\"}\n",
        "    #'<unk>': 0, 3: 1, 2: 2, 4: 3, 5: 4, 1: 5\n",
        "    categories = {0: \"unknown\", 1:\"neutral\", 2:\"negative\", 3:\"positive\", 4:\"very positive\", 5:\"very negative\"}\n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor)\n",
        "\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXuzxT-CFN0h",
        "outputId": "01218bbf-f124-46ad-c2bb-60903ab947b9"
      },
      "source": [
        "for i in range(10):\n",
        "  print(test.sentence[i])\n",
        "  print(\"predicted: \", classify_sentence(test.sentence[i]))\n",
        "  print(\"actual: \", test.sentiments[i])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bon apptit \n",
            "predicted:  neutral\n",
            "actual:  3\n",
            "one-of-a-kind near-masterpiece \n",
            "predicted:  neutral\n",
            "actual:  3\n",
            "for movie lovers as well as opera lovers  tosca is a real treat \n",
            "predicted:  neutral\n",
            "actual:  2\n",
            "excellent performances from jacqueline bisset and martha plimpton grace this deeply touching melodrama \n",
            "predicted:  neutral\n",
            "actual:  3\n",
            " a story  an old and scary one  about the monsters we make  and the vengeance they take \n",
            "predicted:  neutral\n",
            "actual:  2\n",
            "a painfully slow cliche-ridden film filled with more holes than clyde barrow s car \n",
            "predicted:  neutral\n",
            "actual:  2\n",
            "a smart  arch and rather cold-blooded comedy \n",
            "predicted:  neutral\n",
            "actual:  3\n",
            "it does nt reach them  but the effort is gratefully received \n",
            "predicted:  neutral\n",
            "actual:  4\n",
            "cremaster  is at once a tough pill to swallow and a minor miracle of self-expression \n",
            "predicted:  neutral\n",
            "actual:  3\n",
            "shadyac shoots his film like an m night shyamalan movie  and he frequently maintains the same snail s pace  he just forgot to add any genuine tension \n",
            "predicted:  neutral\n",
            "actual:  3\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}