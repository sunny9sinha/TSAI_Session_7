{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session7_Assignment_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ADsz2HZjUJlQdXM6zpHHgQgbZJ-uivO9",
      "authorship_tag": "ABX9TyPOyCmwYEKWq4VYnXWeezuH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunny9sinha/TSAI_Session_7/blob/main/Session7_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfLoK_Dse1w7"
      },
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4ZjO9vPJ49z"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        \n",
        "        super().__init__()          \n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # LSTM layer\n",
        "        self.encoder = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        # try using nn.GRU or nn.RNN here and compare their performances\n",
        "        # try bidirectional and compare their performances\n",
        "        \n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [batch size, sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        # packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.encoder(packed_embedded)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "    \n",
        "        # Hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs = self.fc(hidden)   \n",
        "        \n",
        "        # Final activation function softmax\n",
        "        output = F.softmax(dense_outputs[0], dim=1)\n",
        "            \n",
        "        return output"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "6bi-LPmhfXBi",
        "outputId": "11d4aec4-3c83-4b97-e59f-123685e27062"
      },
      "source": [
        "sentences = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Session5/stanfordSentimentTreebank/datasetSentences.txt',sep='\\t')\n",
        "sentences.head()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_index                                           sentence\n",
              "0               1  The Rock is destined to be the 21st Century 's...\n",
              "1               2  The gorgeously elaborate continuation of `` Th...\n",
              "2               3                     Effective but too-tepid biopic\n",
              "3               4  If you sometimes like to go to the movies to h...\n",
              "4               5  Emerges as something rare , an issue movie tha..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1MlztN6b3OL",
        "outputId": "62c520ec-327f-4b84-9a00-1646446d15f6"
      },
      "source": [
        "sentences.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11855, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "PBc9KehEg2bF",
        "outputId": "fa24548f-7f62-4c86-a12a-c255a06ea7bc"
      },
      "source": [
        "sentiment = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Session5/stanfordSentimentTreebank/sentiment_labels.txt',sep='|',skiprows=[0],names=['phrase_id','sentiment_values'])\n",
        "sentiment.head()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase_id</th>\n",
              "      <th>sentiment_values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.44444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.42708</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   phrase_id  sentiment_values\n",
              "0          0           0.50000\n",
              "1          1           0.50000\n",
              "2          2           0.44444\n",
              "3          3           0.50000\n",
              "4          4           0.42708"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILypkYOuhXzf"
      },
      "source": [
        "sentiment_class = []\n",
        "for i in sentiment['sentiment_values'] :\n",
        "  if i >=0 and i<0.2:\n",
        "    sentiment_class.append(1)\n",
        "  elif i>=0.2 and i<0.4:\n",
        "    sentiment_class.append(2)\n",
        "  elif i>=0.4 and i<0.6:\n",
        "    sentiment_class.append(3)\n",
        "  elif i>=0.6 and i<0.8:\n",
        "    sentiment_class.append(4)\n",
        "  else:\n",
        "    sentiment_class.append(5)\n",
        "\n",
        "sentiment['sentiment_values'] = sentiment_class\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "zn4_U2oyiM7P",
        "outputId": "8147a10c-561c-4fdd-fcba-22471a7c3fe6"
      },
      "source": [
        "sentiment.describe()\n",
        "#sentiment = pd.DataFrame(sentiment)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase_id</th>\n",
              "      <th>sentiment_values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>239232.000000</td>\n",
              "      <td>239232.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>119615.500000</td>\n",
              "      <td>3.062391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>69060.474137</td>\n",
              "      <td>0.911298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>59807.750000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>119615.500000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>179423.250000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>239231.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           phrase_id  sentiment_values\n",
              "count  239232.000000     239232.000000\n",
              "mean   119615.500000          3.062391\n",
              "std     69060.474137          0.911298\n",
              "min         0.000000          1.000000\n",
              "25%     59807.750000          3.000000\n",
              "50%    119615.500000          3.000000\n",
              "75%    179423.250000          4.000000\n",
              "max    239231.000000          5.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "EXhzbsUAYaI7",
        "outputId": "feac487b-f767-4bd2-d46a-064cdeac412a"
      },
      "source": [
        "dictionary = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Session5/stanfordSentimentTreebank/dictionary.txt',sep='|', names=['phrase','phrase_id'])\n",
        "dictionary.head()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase</th>\n",
              "      <th>phrase_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>! '</td>\n",
              "      <td>22935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>! ''</td>\n",
              "      <td>18235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>! Alas</td>\n",
              "      <td>179257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>! Brilliant</td>\n",
              "      <td>22936</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        phrase  phrase_id\n",
              "0            !          0\n",
              "1          ! '      22935\n",
              "2         ! ''      18235\n",
              "3       ! Alas     179257\n",
              "4  ! Brilliant      22936"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FigP7MY-YwC3"
      },
      "source": [
        "def pre_process_sentences(string):\n",
        "  string=string.replace('-LRB-','(')\n",
        "  string=string.replace('-RRB-',')')\n",
        "  string=string.replace('Â', '')\n",
        "  string=string.replace('Ã©', 'e')\n",
        "  string=string.replace('Ã¨', 'e')\n",
        "  string=string.replace('Ã¯', 'i')\n",
        "  string=string.replace('Ã³', 'o')\n",
        "  string=string.replace('Ã´', 'o')\n",
        "  string=string.replace('Ã¶', 'o')\n",
        "  string=string.replace('Ã±', 'n')\n",
        "  string=string.replace('Ã¡', 'a')\n",
        "  string=string.replace('Ã¢', 'a')\n",
        "  string=string.replace('Ã£', 'a')\n",
        "  string=string.replace('\\xc3\\x83\\xc2\\xa0', 'a')\n",
        "  string=string.replace('Ã¼', 'u')\n",
        "  string=string.replace('Ã»', 'u')\n",
        "  string=string.replace('Ã§', 'c')\n",
        "  string=string.replace('Ã¦', 'ae')\n",
        "  string=string.replace('Ã­', 'i')\n",
        "  string=string.replace('\\xa0', ' ')\n",
        "  string=string.replace('\\xc2', '')\n",
        "  return string"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XfbUCCzY1MB"
      },
      "source": [
        "sentences['sentence'] = sentences['sentence'].apply(pre_process_sentences)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5TL1SC7ZH1j"
      },
      "source": [
        "def pre_process_phrases(string):\n",
        "    string=string.replace('é','e')\n",
        "    string=string.replace('è','e')\n",
        "    string=string.replace('ï','i')\n",
        "    string=string.replace('í','i')\n",
        "    string=string.replace('ó','o')\n",
        "    string=string.replace('ô','o')\n",
        "    string=string.replace('ö','o')\n",
        "    string=string.replace('á','a')\n",
        "    string=string.replace('â','a')\n",
        "    string=string.replace('ã','a')\n",
        "    string=string.replace('à','a')\n",
        "    string=string.replace('ü','u')\n",
        "    string=string.replace('û','u')\n",
        "    string=string.replace('ñ','n')\n",
        "    string=string.replace('ç','c')\n",
        "    string=string.replace('æ','ae')\n",
        "    string=string.replace('\\xa0', ' ')\n",
        "    string=string.replace('\\xc2', '')    \n",
        "    return string"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkCsiInVZJMt"
      },
      "source": [
        "dictionary['phrase'] = dictionary['phrase'].apply(pre_process_phrases)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgKgKFQMZvkJ",
        "outputId": "d1f6fa36-9c3e-41cc-f461-dd7551235112"
      },
      "source": [
        "dataset = pd.merge(sentiment,dictionary,on='phrase_id')\n",
        "dataset = dataset.drop(columns=['phrase_id'])\n",
        "print(dataset.head())"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   sentiment_values               phrase\n",
            "0                 3                    !\n",
            "1                 3                    '\n",
            "2                 3                  ' (\n",
            "3                 3    ' ( the cockettes\n",
            "4                 3  ' ( the cockettes )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEQqoUbZdqfs",
        "outputId": "b0593bf6-6f1b-46dd-b315-72ceb72f7e3a"
      },
      "source": [
        "dataset_1 = pd.merge(left = dataset, right = sentences,left_on='phrase',right_on='sentence')\n",
        "dataset_1 = dataset_1.drop(columns=['phrase'])\n",
        "dataset_1.rename(columns = {'sentiment_values':'sentiments'}, inplace = True)\n",
        "print(dataset_1.shape)\n",
        "print(dataset_1.head())\n",
        "print(dataset.columns)\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11854, 3)\n",
            "   sentiments  ...                                           sentence\n",
            "0           1  ...              ... a bland murder-on-campus yawner .\n",
            "1           2  ...  ... a hollow joke told by a cinematic gymnast ...\n",
            "2           3  ...  ... the picture 's cleverness is ironically mu...\n",
            "3           5  ...      classic cinema served up with heart and humor\n",
            "4           2  ...              entertaining enough , but nothing new\n",
            "\n",
            "[5 rows x 3 columns]\n",
            "Index(['sentiment_values', 'phrase'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccuG1cmm442m"
      },
      "source": [
        "def smallCase(data):\n",
        "  for i in data.index:\n",
        "    data['sentence'][i] = data['sentence'][i].lower()\n",
        "  return data"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhoH0Y-CynR-",
        "outputId": "faebf930-467f-4ddf-ac08-c6502283c7fa"
      },
      "source": [
        "import re\n",
        "def cleanText(data):\n",
        "  data_small_case = smallCase(data)\n",
        "  for i in data_small_case.index:\n",
        "    data_small_case.sentence[i] = re.sub(\"[^-9A-Za-z ]\", \"\" , data_small_case.sentence[i])\n",
        "\n",
        "  return data_small_case\n",
        "\n",
        "dataset = cleanText(dataset_1)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "5aTW7lDg87Yw",
        "outputId": "668d4111-c2e7-42a1-fa19-c7e13e8228ee"
      },
      "source": [
        "dataset = dataset.drop(columns=['sentence_index'])\n",
        "dataset.head(10)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiments</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>a bland murder-on-campus yawner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>a hollow joke told by a cinematic gymnast hav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>the picture s cleverness is ironically muted ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>classic cinema served up with heart and humor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>entertaining enough  but nothing new</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>insightfully written  delicately performed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>ordinary melodrama that is heavy on religious ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5</td>\n",
              "      <td>a roller-coaster ride of a movie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5</td>\n",
              "      <td>there are enough moments of heartbreaking hon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4</td>\n",
              "      <td>friends   couples   miles  and all the pabst ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiments                                           sentence\n",
              "0           1                   a bland murder-on-campus yawner \n",
              "1           2   a hollow joke told by a cinematic gymnast hav...\n",
              "2           3   the picture s cleverness is ironically muted ...\n",
              "3           5      classic cinema served up with heart and humor\n",
              "4           2               entertaining enough  but nothing new\n",
              "5           5         insightfully written  delicately performed\n",
              "6           1  ordinary melodrama that is heavy on religious ...\n",
              "7           5                   a roller-coaster ride of a movie\n",
              "8           5   there are enough moments of heartbreaking hon...\n",
              "9           4   friends   couples   miles  and all the pabst ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ5B3Hzgf8Ub"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(dataset, test_size=0.3)\n",
        "train = train.reset_index().drop(columns=['index'])\n",
        "test = test.reset_index().drop(columns=['index'])"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S-fho7Vgy6R",
        "outputId": "30fbe701-ad8d-4c66-d3c6-6e023cee752d"
      },
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8297, 2)\n",
            "(3557, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFDmN6Rc-Nu4",
        "outputId": "38e516b1-2ab0-4946-e9b1-5ab7e65daf0c"
      },
      "source": [
        "test.sentence[1:10]"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    niccol the filmmaker merges his collaborators ...\n",
              "2                                       it s a trifle \n",
              "3    it aimlessly and unsuccessfully attempts to fu...\n",
              "4                                      fun and nimble \n",
              "5                       originality is sorely lacking \n",
              "6                                  viva le resistance \n",
              "7                        a well-executed spy-thriller \n",
              "8    the inherent limitations of using a video game...\n",
              "9    it s a rollicking adventure for you and all yo...\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2RqZ-tY7EGQ",
        "outputId": "81be168e-52f0-4e1d-f457-11c0d571ee8e"
      },
      "source": [
        "# Import Library\n",
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext import data \n",
        "\n",
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fd1c1873690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQccyyC97mWK"
      },
      "source": [
        "sentence = torchtext.legacy.data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "sentiments = torchtext.legacy.data.Field(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkUjjQXK8RZf"
      },
      "source": [
        "fields = [('sentence', sentence),('sentiments',sentiments)]"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUn_viES9Kc5"
      },
      "source": [
        "example = [torchtext.legacy.data.Example.fromlist([train.sentence[i],train.sentiments[i]], fields) for i in range(train.shape[0])] "
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeOydW1cEQO4"
      },
      "source": [
        "trainDataset = torchtext.legacy.data.Dataset(example, fields)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl32EtxiFXXp"
      },
      "source": [
        "example = [torchtext.legacy.data.Example.fromlist([test.sentence[i],test.sentiments[i]], fields) for i in range(test.shape[0])] "
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY7vJroKFsFB"
      },
      "source": [
        "testDataset = torchtext.legacy.data.Dataset(example, fields)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgK4Qo2-F1yA",
        "outputId": "0c999753-3851-439b-a3a3-21a5c6cd2edd"
      },
      "source": [
        "vars(trainDataset.examples[10])"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence': ['a',\n",
              "  'visually',\n",
              "  'flashy',\n",
              "  'but',\n",
              "  'narratively',\n",
              "  'opaque',\n",
              "  'and',\n",
              "  'emotionally',\n",
              "  'vapid',\n",
              "  'exercise',\n",
              "  'in',\n",
              "  'style',\n",
              "  'and',\n",
              "  'mystification'],\n",
              " 'sentiments': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A15FtRYpHbGA"
      },
      "source": [
        "sentence.build_vocab(trainDataset)\n",
        "sentiments.build_vocab(trainDataset)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-kW8cFGIVs4",
        "outputId": "f56d4aab-0d4d-4415-bf3b-977418da2958"
      },
      "source": [
        "print('Size of input vocab : ', len(sentence.vocab))\n",
        "print('Size of label vocab : ', len(sentiments.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(sentence.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', sentiments.vocab.stoi)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  15092\n",
            "Size of label vocab :  6\n",
            "Top 10 words appreared repeatedly : [(' ', 9361), ('the', 7219), ('a', 5155), ('and', 4418), ('of', 4337), ('to', 3006), ('-', 2739), ('s', 2512), ('is', 2489), ('it', 2446)]\n",
            "Labels :  defaultdict(<bound method Vocab._default_unk_index of <torchtext.legacy.vocab.Vocab object at 0x7fd1652bdad0>>, {'<unk>': 0, 4: 1, 2: 2, 3: 3, 5: 4, 1: 5})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yRABmGUI29v"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk38rlxOJAm7"
      },
      "source": [
        "train_iterator, test_iterator = torchtext.legacy.data.BucketIterator.splits((trainDataset, testDataset), batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.sentence),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJFYU6cAJaN6"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(sentence.vocab.stoi, tokens)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj9q1XWcNwHy"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(sentence.vocab)\n",
        "embedding_dim = 200\n",
        "num_hidden_nodes = 300\n",
        "num_output_nodes = 6\n",
        "num_layers = 4\n",
        "dropout = 0.4\n",
        "\n",
        "# Instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers, dropout = dropout)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9BEJoIgOG4W",
        "outputId": "da852b2e-03a3-41d6-9eed-d750f86f3688"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(15092, 200)\n",
            "  (encoder): LSTM(200, 300, num_layers=4, batch_first=True, dropout=0.4)\n",
            "  (fc): Linear(in_features=300, out_features=6, bias=True)\n",
            ")\n",
            "The model has 5,789,806 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LUXLZIVOPKG"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def categorical_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtV0AFllOc1S"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        # retrieve text and no. of words\n",
        "        sentence, sentence_lengths = batch.sentence  \n",
        "        # convert to 1D tensor\n",
        "        predictions = model(sentence, sentence_lengths).squeeze()  \n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.sentiments)        \n",
        "        # compute the binary accuracy\n",
        "        acc = categorical_accuracy(predictions, batch.sentiments)   \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuQPSX3LPEBA"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            sentence, sentence_lengths = batch.sentence\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(sentence, sentence_lengths).squeeze()\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.sentiments)\n",
        "            acc = categorical_accuracy(predictions, batch.sentiments)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzKZXmUdTDo-",
        "outputId": "4bd9b31e-a512-44a4-fd02-461da342d002"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "best_test_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if test_loss < best_test_loss:\n",
        "        best_test_loss = test_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Test. Loss: {test_loss:.3f} |  Test. Acc: {test_acc*100:.2f}% \\n')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 1.741 | Train Acc: 26.47%\n",
            "\t Test. Loss: 1.715 |  Test. Acc: 30.17% \n",
            "\n",
            "\tTrain Loss: 1.706 | Train Acc: 32.45%\n",
            "\t Test. Loss: 1.724 |  Test. Acc: 29.19% \n",
            "\n",
            "\tTrain Loss: 1.681 | Train Acc: 35.17%\n",
            "\t Test. Loss: 1.694 |  Test. Acc: 32.52% \n",
            "\n",
            "\tTrain Loss: 1.651 | Train Acc: 38.59%\n",
            "\t Test. Loss: 1.680 |  Test. Acc: 34.54% \n",
            "\n",
            "\tTrain Loss: 1.623 | Train Acc: 41.69%\n",
            "\t Test. Loss: 1.681 |  Test. Acc: 34.20% \n",
            "\n",
            "\tTrain Loss: 1.594 | Train Acc: 45.05%\n",
            "\t Test. Loss: 1.669 |  Test. Acc: 35.90% \n",
            "\n",
            "\tTrain Loss: 1.559 | Train Acc: 49.01%\n",
            "\t Test. Loss: 1.677 |  Test. Acc: 33.77% \n",
            "\n",
            "\tTrain Loss: 1.526 | Train Acc: 52.89%\n",
            "\t Test. Loss: 1.668 |  Test. Acc: 35.68% \n",
            "\n",
            "\tTrain Loss: 1.489 | Train Acc: 56.87%\n",
            "\t Test. Loss: 1.663 |  Test. Acc: 36.29% \n",
            "\n",
            "\tTrain Loss: 1.456 | Train Acc: 60.22%\n",
            "\t Test. Loss: 1.681 |  Test. Acc: 34.09% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_5TRZ9lBFmX"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_sentence(sentence):\n",
        "    \n",
        "    #categories = {0: \"very negative\", 1:\"negative\", 2:\"neutral\", 3:\"positive\", 4:\"very positive\"}\n",
        "    #'<unk>': 0, 3: 1, 2: 2, 4: 3, 5: 4, 1: 5\n",
        "    categories = {0: \"unknown\", 1:\"neutral\", 2:\"negative\", 3:\"positive\", 4:\"very positive\", 5:\"very negative\"}\n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor)\n",
        "\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXuzxT-CFN0h",
        "outputId": "3bf96c4b-c503-4d64-c358-be5e5591499c"
      },
      "source": [
        "for i in range(10):\n",
        "  print(test.sentence[i])\n",
        "  print(\"predicted: \", classify_sentence(test.sentence[i]))\n",
        "  print(\"actual: \", test.sentiments[i])"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "at the film s centre is a precisely layered performance by an actor in his mid-seventies  michel piccoli \n",
            "predicted:  very positive\n",
            "actual:  3\n",
            "niccol the filmmaker merges his collaborators  symbolic images with his words  insinuating  for example  that in hollywood  only god speaks to the press\n",
            "predicted:  negative\n",
            "actual:  4\n",
            "it s a trifle \n",
            "predicted:  very positive\n",
            "actual:  3\n",
            "it aimlessly and unsuccessfully attempts to fuse at least three dull plots into one good one \n",
            "predicted:  negative\n",
            "actual:  1\n",
            "fun and nimble \n",
            "predicted:  neutral\n",
            "actual:  5\n",
            "originality is sorely lacking \n",
            "predicted:  negative\n",
            "actual:  2\n",
            "viva le resistance \n",
            "predicted:  negative\n",
            "actual:  4\n",
            "a well-executed spy-thriller \n",
            "predicted:  positive\n",
            "actual:  5\n",
            "the inherent limitations of using a video game as the source material movie are once again made all too clear in this schlocky horroraction hybrid \n",
            "predicted:  negative\n",
            "actual:  2\n",
            "it s a rollicking adventure for you and all your mateys  regardless of their ages \n",
            "predicted:  neutral\n",
            "actual:  5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}